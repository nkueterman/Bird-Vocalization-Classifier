{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Vocalization Classifier\n",
    " Transfer learning approach to classifying species via bird vocalization audio spectrograms.\n",
    " \n",
    "![bird spectrograms](bird_spect.png)\n",
    "\n",
    "## Abstract\n",
    "Deep learning is an emerging field that has shown promising results for image classification.  The focus of this study was to analyze the performance of modern machine learning algorithms in the application of classifying bird species from recorded calls.  Bird songs are specific to each species and have a distinct signature, which was the aspect of the data being leveraged.  The data set was collected by various bird enthusiasts and uploaded to xeno-canto.org where the files are open to the public. Statistical analysis was performed on these calls and predictions were made on which species produced the audio which were limited to American Robins and Mourning Doves.  An audio spectrogram served as the input image to the neural networks while the raw audio signal was used for template matching.  The technique that had the highest accuracy was the transfer learning approach, which utilized the pre-existing neural network known as AlexNet.  The shallow neural net had a slightly lower accuracy, while the rudimentary Spectral Angle Mapper (SAM) classifier performed at the lowest accuracy.  All the classification techniques utilized have associated trade-offs which are explored in the conclusion of this study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AlexNet\n",
    "![AlexNet](AlexNet-1.png)\n",
    "https://www.learnopencv.com/understanding-alexnet/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compileAlexNet(numClasses,learningRate) :\n",
    "\n",
    "    # Define base model (AlexNet)\n",
    "    IMG_SHAPE = (224, 224, 3)\n",
    "\n",
    "    #Instantiate an empty model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96, input_shape=(IMG_SHAPE), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # Passing it to a Fully Connected layer\n",
    "    model.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    model.add(Dense(4096, input_shape=(IMG_SHAPE[0]*IMG_SHAPE[1]*IMG_SHAPE[2],)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.4))\n",
    "\n",
    "    # 2nd Fully Connected Layer\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.4))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(numClasses))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss      = keras.losses.categorical_crossentropy,\n",
    "                  optimizer = keras.optimizers.Adam(lr=learningRate),\n",
    "                  metrics   = [\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Defining Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def defineGenerators(dataSet, targSize, shear=0.2, zoom=0.2, horzFlip=True) :\n",
    "    \n",
    "    if targSize[2] == 1 :\n",
    "        colorType = \"grayscale\"\n",
    "    else :\n",
    "        colorType = \"rgb\"\n",
    "    \n",
    "    # Define Generators\n",
    "    train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    shear_range=shear,\n",
    "                    zoom_range=zoom,\n",
    "                    horizontal_flip=horzFlip)\n",
    "\n",
    "    valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Define Data Flow\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=\"C:/Users/Nathan Kueterman/Documents/bird_GAN_python/2 Class/\"+dataSet+\"/Train/\",\n",
    "        target_size=(targSize[0:2]),\n",
    "        color_mode=colorType,\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "        directory=\"C:/Users/Nathan Kueterman/Documents/bird_GAN_python/2 Class/\"+dataSet+\"/Valid/\",\n",
    "        target_size=(targSize[0:2]),\n",
    "        color_mode=colorType,\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=\"C:/Users/Nathan Kueterman/Documents/bird_GAN_python/2 Class/\"+dataSet+\"/Test/\",\n",
    "        target_size=(targSize[0:2]),\n",
    "        color_mode=colorType,\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        seed=42)\n",
    "    \n",
    "    return train_generator,valid_generator,test_generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance Using Only Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "28/28 [==============================] - 10s 342ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6927 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 9s 334ms/step - loss: 0.6917 - accuracy: 0.5090 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 9s 324ms/step - loss: 0.6908 - accuracy: 0.5102 - val_loss: 0.6892 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 9s 323ms/step - loss: 0.6872 - accuracy: 0.5113 - val_loss: 0.6846 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 9s 320ms/step - loss: 0.6781 - accuracy: 0.5564 - val_loss: 0.6552 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 9s 325ms/step - loss: 0.6252 - accuracy: 0.6953 - val_loss: 0.4709 - val_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 9s 319ms/step - loss: 0.5211 - accuracy: 0.7562 - val_loss: 0.3592 - val_accuracy: 0.8594\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4375 - accuracy: 0.8318 - val_loss: 0.3149 - val_accuracy: 0.8594\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 9s 324ms/step - loss: 0.4206 - accuracy: 0.8149 - val_loss: 0.2909 - val_accuracy: 0.9062\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 9s 334ms/step - loss: 0.3541 - accuracy: 0.8646 - val_loss: 0.3106 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 9s 318ms/step - loss: 0.3228 - accuracy: 0.8600 - val_loss: 0.3103 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 10s 356ms/step - loss: 0.3453 - accuracy: 0.8393 - val_loss: 0.3086 - val_accuracy: 0.9062\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 9s 326ms/step - loss: 0.3261 - accuracy: 0.8691 - val_loss: 0.3159 - val_accuracy: 0.8906\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.3422 - accuracy: 0.8442 - val_loss: 0.3409 - val_accuracy: 0.9062\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 9s 319ms/step - loss: 0.2912 - accuracy: 0.8849 - val_loss: 0.3266 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.3139 - accuracy: 0.8679 - val_loss: 0.3321 - val_accuracy: 0.8906\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 9s 325ms/step - loss: 0.2847 - accuracy: 0.8815 - val_loss: 0.3328 - val_accuracy: 0.9062\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 9s 321ms/step - loss: 0.2912 - accuracy: 0.8790 - val_loss: 0.4467 - val_accuracy: 0.9062\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 9s 320ms/step - loss: 0.3037 - accuracy: 0.8736 - val_loss: 0.3364 - val_accuracy: 0.8750\n",
      "80/80 [==============================] - 1s 10ms/step\n",
      "Confusion matrix:\n",
      "[[36  4]\n",
      " [ 3 37]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model - Only Real Data\n",
    "train_generator,valid_generator,test_generator = defineGenerators(\"Gray\", [224,224,3])\n",
    "\n",
    "# Instantiate Model\n",
    "model1 = compileAlexNet(train_generator.num_classes,1e-5)\n",
    "\n",
    "# Train\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "model1.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20)\n",
    "\n",
    "model1.evaluate_generator(generator=valid_generator,\n",
    "                         steps=STEP_SIZE_VALID)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred = model1.predict_generator(test_generator,\n",
    "                             steps=STEP_SIZE_TEST,\n",
    "                             verbose=1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# display test results\n",
    "confMat1 = confusion_matrix(test_generator.classes, predicted_class_indices)\n",
    "print(\"Confusion matrix:\\n%s\" % confMat1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance Using Only Synthetic Data\n",
    "![gan spectrograms](robin_dove_comparison.png)\n",
    "<center>Synthetic Spectrograms: American Robin (left) vs Mourning Dove (right)</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1996 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 21s 338ms/step - loss: 0.6874 - accuracy: 0.5453 - val_loss: 0.6859 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 22s 347ms/step - loss: 0.6455 - accuracy: 0.5728 - val_loss: 0.5072 - val_accuracy: 0.9219\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 21s 339ms/step - loss: 0.3568 - accuracy: 0.8574 - val_loss: 0.1795 - val_accuracy: 0.9375\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 21s 339ms/step - loss: 0.2031 - accuracy: 0.9252 - val_loss: 0.1154 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 21s 341ms/step - loss: 0.1324 - accuracy: 0.9506 - val_loss: 0.0843 - val_accuracy: 0.9844\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 21s 337ms/step - loss: 0.1238 - accuracy: 0.9506 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 21s 337ms/step - loss: 0.1042 - accuracy: 0.9557 - val_loss: 0.0975 - val_accuracy: 0.9844\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 21s 342ms/step - loss: 0.0914 - accuracy: 0.9623 - val_loss: 0.1113 - val_accuracy: 0.9688\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 21s 338ms/step - loss: 0.0683 - accuracy: 0.9771 - val_loss: 0.1249 - val_accuracy: 0.9375\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 21s 335ms/step - loss: 0.0699 - accuracy: 0.9735 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 21s 338ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 21s 337ms/step - loss: 0.0523 - accuracy: 0.9801 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 21s 342ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 21s 341ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 21s 335ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 21s 343ms/step - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.0702 - val_accuracy: 0.9844\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 22s 350ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 21s 339ms/step - loss: 0.0233 - accuracy: 0.9943 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 21s 341ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 21s 340ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0539 - val_accuracy: 0.9688\n",
      "80/80 [==============================] - 1s 9ms/step\n",
      "Confusion matrix:\n",
      "[[37  3]\n",
      " [ 3 37]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model - Only Synthetic Data\n",
    "train_generator,valid_generator,test_generator = defineGenerators(\"GAN\", [224,224,3])\n",
    "\n",
    "# Instantiate Model\n",
    "model2 = compileAlexNet(train_generator.num_classes,1e-5)\n",
    "\n",
    "# Train\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "model2.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20)\n",
    "\n",
    "model2.evaluate_generator(generator=valid_generator,\n",
    "                         steps=STEP_SIZE_VALID)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred = model2.predict_generator(test_generator,\n",
    "                                steps=STEP_SIZE_TEST,\n",
    "                                verbose=1)\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# display test results\n",
    "confMat2 = confusion_matrix(test_generator.classes, predicted_class_indices)\n",
    "print(\"Confusion matrix:\\n%s\" % confMat2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance Using Both Real and Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1759 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 19s 348ms/step - loss: 0.6910 - accuracy: 0.5171 - val_loss: 0.6895 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 18s 342ms/step - loss: 0.6741 - accuracy: 0.5628 - val_loss: 0.6843 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 18s 338ms/step - loss: 0.4739 - accuracy: 0.7973 - val_loss: 0.4444 - val_accuracy: 0.7812\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 19s 344ms/step - loss: 0.3549 - accuracy: 0.8431 - val_loss: 0.3795 - val_accuracy: 0.7656\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 18s 334ms/step - loss: 0.2709 - accuracy: 0.8964 - val_loss: 0.4566 - val_accuracy: 0.7812\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 18s 335ms/step - loss: 0.2601 - accuracy: 0.8975 - val_loss: 0.2578 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 18s 340ms/step - loss: 0.2412 - accuracy: 0.8992 - val_loss: 0.3347 - val_accuracy: 0.7969\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 0.1992 - accuracy: 0.9253 - val_loss: 0.2044 - val_accuracy: 0.9375\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 19s 346ms/step - loss: 0.1914 - accuracy: 0.9259 - val_loss: 0.1743 - val_accuracy: 0.9219\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 0.1685 - accuracy: 0.9409 - val_loss: 0.1590 - val_accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 19s 351ms/step - loss: 0.1766 - accuracy: 0.9340 - val_loss: 0.1709 - val_accuracy: 0.8906\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 19s 346ms/step - loss: 0.1694 - accuracy: 0.9380 - val_loss: 0.2148 - val_accuracy: 0.9375\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 18s 342ms/step - loss: 0.1729 - accuracy: 0.9299 - val_loss: 0.2351 - val_accuracy: 0.9062\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 18s 335ms/step - loss: 0.1613 - accuracy: 0.9409 - val_loss: 0.1423 - val_accuracy: 0.9219\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 18s 332ms/step - loss: 0.1594 - accuracy: 0.9380 - val_loss: 0.1334 - val_accuracy: 0.9375\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 18s 326ms/step - loss: 0.1272 - accuracy: 0.9537 - val_loss: 0.1757 - val_accuracy: 0.9062\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 18s 329ms/step - loss: 0.1435 - accuracy: 0.9421 - val_loss: 0.1249 - val_accuracy: 0.9688\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 18s 327ms/step - loss: 0.1231 - accuracy: 0.9514 - val_loss: 0.1277 - val_accuracy: 0.9531\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 18s 326ms/step - loss: 0.1208 - accuracy: 0.9572 - val_loss: 0.1126 - val_accuracy: 0.9531\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 18s 325ms/step - loss: 0.1224 - accuracy: 0.9548 - val_loss: 0.1276 - val_accuracy: 0.9531\n",
      "80/80 [==============================] - 1s 9ms/step\n",
      "Confusion matrix:\n",
      "[[40  0]\n",
      " [ 2 38]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model - Both Real and Synthetic Data\n",
    "train_generator,valid_generator,test_generator = defineGenerators(\"Combined\", [224,224,3])\n",
    "\n",
    "# Instantiate Model\n",
    "model3 = compileAlexNet(train_generator.num_classes,1e-5)\n",
    "\n",
    "# Train\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "model3.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20)\n",
    "\n",
    "model3.evaluate_generator(generator=valid_generator,\n",
    "                          steps=STEP_SIZE_VALID)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred = model3.predict_generator(test_generator,\n",
    "                                steps=STEP_SIZE_TEST,\n",
    "                                verbose=1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# display test results\n",
    "confMat3 = confusion_matrix(test_generator.classes, predicted_class_indices)\n",
    "print(\"Confusion matrix:\\n%s\" % confMat3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
